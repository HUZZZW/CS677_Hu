{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv(\"NVDA_weekly_return_volatility.csv\")\n",
    "year=df['Year'].unique()\n",
    "Q1_label=[]\n",
    "yearly_mean=df.groupby('Year')['mean_return'].mean().values\n",
    "for i in range(len(year)):\n",
    "    for j in range(len(df)):\n",
    "        if df['Year'][j]==year[i] and df[\"mean_return\"][j]>yearly_mean[i]:\n",
    "            Q1_label.append('green')\n",
    "        elif df['Year'][j]==year[i]:\n",
    "            Q1_label.append('red')\n",
    "df['label']=Q1_label\n",
    "Q1_X=df[df[\"Year\"]==2017][[\"mean_return\",\"volatility\"]]\n",
    "Q1_y=df[df[\"Year\"]==2017][\"label\"]\n",
    "Q2_X=df.loc[df[\"Year\"]==2018][[\"mean_return\",\"volatility\"]]\n",
    "Q2_y=df.loc[df[\"Year\"]==2018][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. take N = 1,...,10 and d = 1,2,...,5. For each value of N and d construct a random tree classifier (use ”entropy” as splitting criteria - this is the default) use your year 1 labels as training set and compute the error rate for year 2. Plot your error rates and find the best combination of N and d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4277732179.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/by/3jf2bh0x2ks63rycd0ctbzsh0000gn/T/ipykernel_81199/4277732179.py\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    print(\"the best n_estimators and max_depth are\",errorrate.index(min(errorrate))10+1,\"and\",errorrate.index(min(errorrate))%5+1)\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "errorrate=[]\n",
    "for i in range(1,11):\n",
    "    for j in range(1,6):\n",
    "        rf=RandomForestClassifier(n_estimators=i,max_depth=j)\n",
    "        rf.fit(Q1_X,Q1_y)\n",
    "        errorrate.append(1-accuracy_score(Q2_y,rf.predict(Q2_X)))\n",
    "        print(\" when n_estimators=\",i,\"max_depth=\",j,\",the accuracy=\",1-accuracy_score(Q2_y,rf.predict(Q2_X)))\n",
    "#plot the error rate\n",
    "plt.plot(range(1,11),errorrate[:10],label=\"max_depth=1\")\n",
    "plt.plot(range(1,11),errorrate[10:20],label=\"max_depth=2\")\n",
    "plt.plot(range(1,11),errorrate[20:30],label=\"max_depth=3\")\n",
    "plt.plot(range(1,11),errorrate[30:40],label=\"max_depth=4\")\n",
    "plt.plot(range(1,11),errorrate[40:50],label=\"max_depth=5\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"error rate\")\n",
    "plt.show()\n",
    "\n",
    "#the best n_estimators and max_depth\n",
    "print(\"the best n_estimators and max_depth are\",errorrate.index(min(errorrate))10+1,\"and\",errorrate.index(min(errorrate))%5+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. using the optimal values from year 1, compute the confusion matrix for year 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confusion matrix for year 2 is\n",
      "[[28  1]\n",
      " [ 0 24]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=errorrate.index(min(errorrate))%10+1,max_depth=errorrate.index(min(errorrate))%5+1)\n",
    "rf.fit(Q1_X,Q1_y)\n",
    "print(\"the confusion matrix for year 2 is\")\n",
    "print(confusion_matrix(Q2_y,rf.predict(Q2_X)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. what is true positive rate and true negative rate for year 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the true positive rate for year 2 is 0.9655172413793104\n",
      "the true negative rate for year 2 is 1.0\n"
     ]
    }
   ],
   "source": [
    "# what is true positive rate and true negative rate for year 2?\n",
    "print(\"the true positive rate for year 2 is\",confusion_matrix(Q2_y,rf.predict(Q2_X))[0][0]/(confusion_matrix(Q2_y,rf.predict(Q2_X))[0][0]+confusion_matrix(Q2_y,rf.predict(Q2_X))[0][1]))\n",
    "print(\"the true negative rate for year 2 is\",confusion_matrix(Q2_y,rf.predict(Q2_X))[1][1]/(confusion_matrix(Q2_y,rf.predict(Q2_X))[1][0]+confusion_matrix(Q2_y,rf.predict(Q2_X))[1][1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9806c24c91b3e4d18e5f3e793847aaaf5646eebdcfa376b540720de17b3c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
